{"cells":[{"cell_type":"markdown","metadata":{"id":"-6wdX_tCPuvT"},"source":["### Language Model and Application for Spelling Error Correction\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMsAOdA5PuvU","executionInfo":{"status":"ok","timestamp":1758726620442,"user_tz":-420,"elapsed":21,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"ee881e60-c747-4846-817c-7e9280a18f18"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"source":["import string, re, math\n","import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from collections import defaultdict, Counter\n","import numpy as np\n","from difflib import get_close_matches\n","import joblib\n","\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"markdown","metadata":{"id":"V7bG40GlPuvX"},"source":["### Cải thiện mô hình sử dụng làm mượt nội suy (Interpolation smoothing) với phương pháp \"Stupid Backoff\"\n","- Sử dụng mô hình NGram\n","- Làm mượt xác suất bằng phương pháp \"Stupid Backoff\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pb6bo4ztPuvX","executionInfo":{"status":"ok","timestamp":1758726670342,"user_tz":-420,"elapsed":49901,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"94198251-e70a-47ff-8181-dda52d7e63e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Số câu: 444404\n"]}],"source":["# Tải dữ liệu\n","with open(\"tedtalk.txt\", \"r\", encoding=\"utf-8\") as f:\n","    docs = f.read()\n","# Tiền xử lý\n","def preprocess(sentence):\n","    # Giữ lại chữ cái, chữ số, và dấu nháy đơn\n","    text = re.sub(r\"[^A-Za-z0-9'\\s]\", \" \", sentence)\n","    # Chuyển về chữ thường\n","    text = text.lower()\n","    # Loại bỏ khoảng trắng thừa\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return word_tokenize(text)\n","# Tách câu\n","sentences = sent_tokenize(docs)\n","# Tiền xử lý từng câu\n","tokenized = [preprocess(s) for s in sentences]\n","print(\"Số câu:\", len(tokenized))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAUPufoTPuvY"},"outputs":[],"source":["class NgramModel:\n","    def __init__(self, n):\n","        self.n = n # Bậc của mô hình\n","        self.model = defaultdict(Counter)  # Lưu trữ n-gram counts\n","        self.vocab = set()  # Tập từ vựng của mô hình\n","\n","    def train(self, sentences):\n","        # sentences: list các câu, mỗi câu là list token\n","        for tokens in sentences:\n","            self.vocab.update(tokens)   # cập nhật vocab\n","            padded = [\"<s>\"]*(self.n-1) + tokens + [\"</s>\"]  # padding đầu/cuối\n","            for i in range(len(padded)-self.n+1):\n","                context = tuple(padded[i:i+self.n-1])  # ngữ cảnh\n","                word = padded[i+self.n-1]  # từ cần dự đoán\n","                self.model[context][word] += 1\n","\n","    # Tính xác suất có điều kiện với Laplace smoothing\n","    def prob(self, context, word):\n","        context_counts = self.model[context]\n","        V = len(self.vocab)\n","        return (context_counts[word] + 1) / (sum(context_counts.values()) + V)\n","    # Tính xác suất của một câu\n","    def sentence_prob(self, sentence):\n","        tokens = [\"<s>\"]*(self.n-1) + preprocess(sentence) + [\"</s>\"]\n","        prob = 1.0\n","        for i in range(len(tokens)-self.n+1):\n","            context = tuple(tokens[i:i+self.n-1])\n","            word = tokens[i+self.n-1]\n","            prob *= self.prob(context, word)\n","        return prob"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6amsF-gyPuvZ","executionInfo":{"status":"ok","timestamp":1758726701465,"user_tz":-420,"elapsed":31118,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"f7c4ecd4-785f-40f7-ce75-fe7979b788f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mô hình Laplace đã được huấn luyện!\n"]}],"source":["unigram = NgramModel(1) # Mô hình 1-gram\n","bigram = NgramModel(2) # Mô hình 2-gram\n","trigram = NgramModel(3) # Mô hình 3-gram\n","# Huấn luyện mô hình\n","unigram.train(tokenized)\n","bigram.train(tokenized)\n","trigram.train(tokenized)\n","print(\"Mô hình Laplace đã được huấn luyện!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSx281HLPuva","executionInfo":{"status":"ok","timestamp":1758726701498,"user_tz":-420,"elapsed":13,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"76cfce51-991f-4897-a9fb-74b313a19d98"},"outputs":[{"output_type":"stream","name":"stdout","text":["1-gram perplexity: 401.6450114268086\n","2-gram perplexity: 564.1016367106075\n","3-gram perplexity: 2408.989014775055\n"]}],"source":["# Tính perplexity\n","def perplexity(model, sentence):\n","    tokens = [\"<s>\"]*(model.n-1) + preprocess(sentence) + [\"</s>\"] # padding\n","    log_prob = 0\n","    N = len(tokens) - (model.n-1) # số từ thực tế\n","    for i in range(len(tokens)-model.n+1): # duyệt qua từng n-gram\n","        context = tuple(tokens[i:i+model.n-1])\n","        word = tokens[i+model.n-1] # từ cần dự đoán\n","        p = model.prob(context, word) # xác suất có điều kiện\n","        log_prob += math.log(p)\n","    return math.exp(-log_prob/N)\n","\n","sentence = \"the climate crisis is real\"\n","print(\"1-gram perplexity:\", perplexity(unigram, sentence))\n","print(\"2-gram perplexity:\", perplexity(bigram, sentence))\n","print(\"3-gram perplexity:\", perplexity(trigram, sentence))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhl5oRpDPuvb","executionInfo":{"status":"ok","timestamp":1758726730008,"user_tz":-420,"elapsed":28513,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"f84b539d-860f-4add-a5e6-04ae6dcdf90a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mô hình Stupid Backoff đã được huấn luyện!\n"]}],"source":["# Mô hình Stupid Backoff\n","class StupidBackoffModel(NgramModel):\n","    def __init__(self, n, alpha=0.4):\n","        super().__init__(n) # Gọi hàm khởi tạo của lớp cha\n","        self.alpha = alpha # Hệ số giảm bậc\n","        self.lower_order = None # Mô hình bậc thấp hơn\n","\n","    def link_lower_order(self, lower_model):\n","        self.lower_order = lower_model\n","\n","    def prob(self, context, word):\n","        if self.model[context][word] > 0: # Nếu n-gram có trong mô hình\n","            return self.model[context][word] / sum(self.model[context].values())\n","        elif self.lower_order:\n","            return self.alpha * self.lower_order.prob(context[1:], word)\n","        else:\n","            return 1 / len(self.vocab)\n","# Huấn luyện mô hình Stupid Backoff\n","sb_trigram = StupidBackoffModel(3)\n","sb_bigram = StupidBackoffModel(2)\n","sb_unigram = StupidBackoffModel(1)\n","\n","sb_trigram.train(tokenized)\n","sb_bigram.train(tokenized)\n","sb_unigram.train(tokenized)\n","# Liên kết các mô hình với nhau\n","sb_trigram.link_lower_order(sb_bigram)\n","sb_bigram.link_lower_order(sb_unigram)\n","print(\"Mô hình Stupid Backoff đã được huấn luyện!\")"]},{"cell_type":"markdown","metadata":{"id":"4jn-kZoSPuvc"},"source":["### So sánh giữa 2 phương pháp làm mượt Laplace vs Stupid Backoff"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYncMpnOPuvc","executionInfo":{"status":"ok","timestamp":1758726730032,"user_tz":-420,"elapsed":23,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"2538b0b5-705b-42d0-a3b1-226328673a8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Laplace Bigram ===\n","Correct: 3.10352923774124e-17\n","Incorrect: 1.7791565158621212e-23\n","\n","=== Stupid Backoff Bigram ===\n","Correct: 6.311251761700601e-12\n","Incorrect: 3.598266099224033e-19\n","\n","=== Laplace Trigram ===\n","Correct: 5.1167132917041455e-21\n","Incorrect: 5.153658419123097e-29\n","\n","=== Stupid Backoff Trigram ===\n","Correct: 1.1463775565573334e-10\n","Incorrect: 3.684624485605411e-21\n"]}],"source":["\n","correct = \"the climate crisis is real\"\n","incorrect = \"climate the crisis real is\"\n","\n","print(\"=== Laplace Bigram ===\")\n","print(\"Correct:\", bigram.sentence_prob(correct))\n","print(\"Incorrect:\", bigram.sentence_prob(incorrect))\n","\n","print(\"\\n=== Stupid Backoff Bigram ===\")\n","print(\"Correct:\", sb_bigram.sentence_prob(correct))\n","print(\"Incorrect:\", sb_bigram.sentence_prob(incorrect))\n","\n","print(\"\\n=== Laplace Trigram ===\")\n","print(\"Correct:\", trigram.sentence_prob(correct))\n","print(\"Incorrect:\", trigram.sentence_prob(incorrect))\n","\n","print(\"\\n=== Stupid Backoff Trigram ===\")\n","print(\"Correct:\", sb_trigram.sentence_prob(correct))\n","print(\"Incorrect:\", sb_trigram.sentence_prob(incorrect))\n"]},{"cell_type":"markdown","metadata":{"id":"UD4jbI_IPuvd"},"source":["- Từ phần kết quả ta thấy được:\n","+ Câu đúng có xác suất cao hơn câu sai ở cả hai phương pháp.\n","+ Stupid Backoff thường phân biệt rõ hơn giữa đúng và sai."]},{"cell_type":"markdown","metadata":{"id":"l1EY_fFPPuvd"},"source":["### Dự đoán từ tiếp theo dựa vào ngữ cảnh cho trước"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmN5frYEPuvd","executionInfo":{"status":"ok","timestamp":1758726795881,"user_tz":-420,"elapsed":65851,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"877b51c8-4250-4e5a-a5f3-ffe74111c800"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('crisis', 0.2831050228310502), ('change', 0.091324200913242), ('is', 0.0410958904109589), ('system', 0.0273972602739726), ('of', 0.0182648401826484)]\n"]}],"source":["def predict_next_word(model, context, topk=5): # Dự đoán từ dựa trên ngữ cảnh\n","    context = tuple(context[-(model.n-1):]) # lấy (n-1) từ cuối của ngữ cảnh\n","    probs = {w: model.prob(context, w) for w in model.vocab}\n","    return sorted(probs.items(), key=lambda x: x[1], reverse=True)[:topk]\n","\n","print(predict_next_word(sb_trigram, [\"the\", \"climate\"]))"]},{"cell_type":"markdown","metadata":{"id":"8nbmi5oDPuvd"},"source":["### Sử dụng hàm tính khoảng cách để sửa lại từ bị sai với thư viện difflib (from difflib import get_close_matches)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnRSx_PqPuvd","executionInfo":{"status":"ok","timestamp":1758726796070,"user_tz":-420,"elapsed":203,"user":{"displayName":"MINH LÊ CÔNG","userId":"05387425346698377898"}},"outputId":"730dcebf-7bea-4205-cd95-aef98385f0ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["development\n"]}],"source":["def correct_word(word, vocab, n=1):\n","    matches = get_close_matches(word, vocab, n=n) # Tìm từ gần đúng nhất\n","    return matches[0] if matches else word\n","\n","print(correct_word(\"devolopmentt\", list(sb_trigram.vocab)))"]},{"cell_type":"code","source":["joblib.dump(unigram, \"laplace_unigram.pkl\")\n","joblib.dump(bigram, \"laplace_bigram.pkl\")\n","joblib.dump(trigram, \"laplace_trigram.pkl\")\n","\n","# Lưu mô hình Stupid Backoff\n","joblib.dump(sb_unigram, \"sb_unigram.pkl\")\n","joblib.dump(sb_bigram, \"sb_bigram.pkl\")\n","joblib.dump(sb_trigram, \"sb_trigram.pkl\")"],"metadata":{"id":"MYs5MYPdk-OZ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}